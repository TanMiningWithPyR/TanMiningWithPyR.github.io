<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Affluence Tan" />

<meta name="date" content="2016-12-29" />

<title>1.KNN分类</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-1.1/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-1.1/highlight.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Affluence Tan</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
    Home
  </a>
</li>
<li>
  <a href="about.html">
    <span class="fa fa-info"></span>
     
    About
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-gear"></span>
     
    More
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="Preface.html">Data Modeling</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/TanMiningWithPyR">
    <span class="fa fa-github"></span>
     
    github
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">1.KNN分类</h1>
<h4 class="author"><em>Affluence Tan</em></h4>
<h4 class="date"><em>December 29, 2016</em></h4>

</div>


<div class="section level2">
<h2>简单理解近邻分类</h2>
<p>近邻分类就是把没有标记（标记可以看做是前言里面的对应的函数中的<span class="math inline">\(Y\)</span>）的案例归类到与它们最相似（或者说是“相近”）的带有标记的案例所在的类里面。</p>
<p>邻近分类是一种有监督学习。</p>
<p>与之有着藕断丝连的关系的是聚类分析，它是一种无监督学习，我们在下一章讲。</p>
<div class="section level3">
<h3>什么是最近</h3>
<p>有很多距离度量，在数学上，一般的说，一个函数<span class="math inline">\(d(x,y)\)</span>，如果满足以下四条性质，就可以看做是距离度量：</p>
<ul>
<li><span class="math inline">\(d(x,x)=0\)</span> // 到自己的距离为0<br />
</li>
<li><span class="math inline">\(d(x,y)&gt;=0\)</span> // 距离非负<br />
</li>
<li><span class="math inline">\(d(x,y)=d(y,x)\)</span> // 对称性: 如果 A 到 B 距离是 a，那么 B 到 A 的距离也应该是 a<br />
</li>
<li><span class="math inline">\(d(x,k)+d(k,y)&gt;=d(x,y)\)</span> // 三角形法则: （两边之和大于第三边）</li>
</ul>
<p>平时我们遇见最多，也是在中学阶段就领会的一种距离叫做欧几里得距离。二维情况公式形如：<span class="math inline">\(d(x,y)=\sqrt{(x_1-x_2)^{2}+(y_1-y_2)^{2}}\)</span></p>
</div>
<div id="k" class="section level3">
<h3>什么是K最近</h3>
<p>K表示邻居的数量，假设K=3，那么就会在3个邻居中投票表决归属哪一类，3个邻居2个是A类，1个是B类，那么未标记的样本将归为A类。</p>
<p>K的选取关系到模型的是过度拟合还是低度拟合。两种情况我们都应该避免。可以考虑两种极端情况，一个是K取训练数据集的样本量，那么样本量多的标签将永远在投票中获胜。反之，k为1，会使得训练数据集中的异常值过度的影响到未标记的案例。</p>
<p>选取k一般为3~10，或者样本量的平方根。</p>
<p>还有一种有趣的想法是权重投票，该方法认为，比较近邻居的投票比比较远的更有效，所以有更大的权重。</p>
</div>
</div>
<div id="r" class="section level2">
<h2>R实战</h2>
<div class="section level3">
<h3>获取数据集</h3>
<pre class="r"><code>library(readr)
wbcd &lt;- read_csv(&quot;wisc_bc_data.csv&quot;)
str(wbcd)</code></pre>
<pre><code>## Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;:    569 obs. of  32 variables:
##  $ id               : int  87139402 8910251 905520 868871 9012568 906539 925291 87880 862989 89827 ...
##  $ diagnosis        : chr  &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; ...
##  $ radius_mean      : num  12.3 10.6 11 11.3 15.2 ...
##  $ texture_mean     : num  12.4 18.9 16.8 13.4 13.2 ...
##  $ perimeter_mean   : num  78.8 69.3 70.9 73 97.7 ...
##  $ area_mean        : num  464 346 373 385 712 ...
##  $ smoothness_mean  : num  0.1028 0.0969 0.1077 0.1164 0.0796 ...
##  $ compactness_mean : num  0.0698 0.1147 0.078 0.1136 0.0693 ...
##  $ concavity_mean   : num  0.0399 0.0639 0.0305 0.0464 0.0339 ...
##  $ points_mean      : num  0.037 0.0264 0.0248 0.048 0.0266 ...
##  $ symmetry_mean    : num  0.196 0.192 0.171 0.177 0.172 ...
##  $ dimension_mean   : num  0.0595 0.0649 0.0634 0.0607 0.0554 ...
##  $ radius_se        : num  0.236 0.451 0.197 0.338 0.178 ...
##  $ texture_se       : num  0.666 1.197 1.387 1.343 0.412 ...
##  $ perimeter_se     : num  1.67 3.43 1.34 1.85 1.34 ...
##  $ area_se          : num  17.4 27.1 13.5 26.3 17.7 ...
##  $ smoothness_se    : num  0.00805 0.00747 0.00516 0.01127 0.00501 ...
##  $ compactness_se   : num  0.0118 0.03581 0.00936 0.03498 0.01485 ...
##  $ concavity_se     : num  0.0168 0.0335 0.0106 0.0219 0.0155 ...
##  $ points_se        : num  0.01241 0.01365 0.00748 0.01965 0.00915 ...
##  $ symmetry_se      : num  0.0192 0.035 0.0172 0.0158 0.0165 ...
##  $ dimension_se     : num  0.00225 0.00332 0.0022 0.00344 0.00177 ...
##  $ radius_worst     : num  13.5 11.9 12.4 11.9 16.2 ...
##  $ texture_worst    : num  15.6 22.9 26.4 15.8 15.7 ...
##  $ perimeter_worst  : num  87 78.3 79.9 76.5 104.5 ...
##  $ area_worst       : num  549 425 471 434 819 ...
##  $ smoothness_worst : num  0.139 0.121 0.137 0.137 0.113 ...
##  $ compactness_worst: num  0.127 0.252 0.148 0.182 0.174 ...
##  $ concavity_worst  : num  0.1242 0.1916 0.1067 0.0867 0.1362 ...
##  $ points_worst     : num  0.0939 0.0793 0.0743 0.0861 0.0818 ...
##  $ symmetry_worst   : num  0.283 0.294 0.3 0.21 0.249 ...
##  $ dimension_worst  : num  0.0677 0.0759 0.0788 0.0678 0.0677 ...</code></pre>
<p>wbcd数据集是一个乳腺癌细胞活检的数据集，一共有592个样本和32个变量。顾名思义，diagnosis变量就是细胞是否癌变的诊断。“M”是恶性，“B”是良性的。</p>
</div>
<div class="section level3">
<h3>探索和准备数据集</h3>
<pre class="r"><code># drop the id feature
wbcd &lt;- wbcd[-1]

# table of diagnosis
table(wbcd$diagnosis)</code></pre>
<pre><code>## 
##   B   M 
## 357 212</code></pre>
<pre class="r"><code># recode diagnosis as a factor
wbcd$diagnosis &lt;- factor(wbcd$diagnosis, levels = c(&quot;B&quot;, &quot;M&quot;),
                         labels = c(&quot;Benign&quot;, &quot;Malignant&quot;))

# table or proportions with more informative labels
round(prop.table(table(wbcd$diagnosis)) * 100, digits = 1)</code></pre>
<pre><code>## 
##    Benign Malignant 
##      62.7      37.3</code></pre>
<p>一共有良性“B”357个，占总数的67.2%。</p>
<pre class="r"><code># summarize three numeric features
summary(wbcd[c(&quot;radius_mean&quot;, &quot;area_mean&quot;, &quot;smoothness_mean&quot;)])</code></pre>
<pre><code>##   radius_mean       area_mean      smoothness_mean  
##  Min.   : 6.981   Min.   : 143.5   Min.   :0.05263  
##  1st Qu.:11.700   1st Qu.: 420.3   1st Qu.:0.08637  
##  Median :13.370   Median : 551.1   Median :0.09587  
##  Mean   :14.127   Mean   : 654.9   Mean   :0.09636  
##  3rd Qu.:15.780   3rd Qu.: 782.7   3rd Qu.:0.10530  
##  Max.   :28.110   Max.   :2501.0   Max.   :0.16340</code></pre>
<pre class="r"><code># normalize the wbcd data
wbcd_n &lt;- as.data.frame(scale(wbcd[,2:31]))

# confirm that normalization worked
summary(wbcd_n[c(&quot;radius_mean&quot;, &quot;area_mean&quot;, &quot;smoothness_mean&quot;)])</code></pre>
<pre><code>##   radius_mean        area_mean       smoothness_mean   
##  Min.   :-2.0279   Min.   :-1.4532   Min.   :-3.10935  
##  1st Qu.:-0.6888   1st Qu.:-0.6666   1st Qu.:-0.71034  
##  Median :-0.2149   Median :-0.2949   Median :-0.03486  
##  Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.00000  
##  3rd Qu.: 0.4690   3rd Qu.: 0.3632   3rd Qu.: 0.63564  
##  Max.   : 3.9678   Max.   : 5.2459   Max.   : 4.76672</code></pre>
<p><em>由于最后的分类取决于距离计算，仔细一想发现它的结果是依赖于变量的量纲，所以我们要利用scale函数将变量标准化处理</em></p>
<p>接下去可以创建数据集了。</p>
<pre class="r"><code># create training and test data
wbcd_train &lt;- wbcd_n[1:469, ]
wbcd_test &lt;- wbcd_n[470:569, ]

# create labels for training and test data

wbcd_train_labels &lt;- wbcd[1:469, 1]
wbcd_test_labels &lt;- wbcd[470:569, 1]</code></pre>
<p>数据集本来就是随机的，不需要随机抽取了，直接切分。</p>
</div>
<div class="section level3">
<h3>基于数据集训练模型</h3>
<pre class="r"><code># load the &quot;class&quot; library
library(class)

wbcd_test_pred &lt;- knn(train = wbcd_train, test = wbcd_test,
                      cl = wbcd_train_labels, k=21)</code></pre>
</div>
<div class="section level3">
<h3>评估模型性能</h3>
<p>模型性能的评估是一个复杂的话题，它可以单独的成为一个章节。我将在单独的一个章节里面讨论。<br />
对于一个分类变量，被称为混淆矩阵(confusion matrix)的东西是一个绕不开的话题。</p>
<p>研究一个混淆矩阵的第一步分阴阳。感兴趣的类别为阳性(positive),其他的类别称为阴性。可能你会觉得奇怪，为什么要分阴阳。个人认为，是因为在模型不能同时提高阴性预测率和阳性预测率的情况下，我们要有所取舍。所以不能只看单一的准确度。比如在本案中，人们一般会对癌细胞更加感兴趣。下面用gmodels包中的CrossTable做一下混淆矩阵。</p>
<pre class="r"><code># load the &quot;gmodels&quot; library
library(gmodels)</code></pre>
<pre><code>## Warning: package &#39;gmodels&#39; was built under R version 3.2.5</code></pre>
<pre class="r"><code># Create the cross tabulation of predicted vs. actual
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred,
           prop.chisq=FALSE)</code></pre>
<pre><code>## 
##  
##    Cell Contents
## |-------------------------|
## |                       N |
## |           N / Row Total |
## |           N / Col Total |
## |         N / Table Total |
## |-------------------------|
## 
##  
## Total Observations in Table:  100 
## 
##  
##                  | wbcd_test_pred 
## wbcd_test_labels |    Benign | Malignant | Row Total | 
## -----------------|-----------|-----------|-----------|
##           Benign |        61 |         0 |        61 | 
##                  |     1.000 |     0.000 |     0.610 | 
##                  |     0.924 |     0.000 |           | 
##                  |     0.610 |     0.000 |           | 
## -----------------|-----------|-----------|-----------|
##        Malignant |         5 |        34 |        39 | 
##                  |     0.128 |     0.872 |     0.390 | 
##                  |     0.076 |     1.000 |           | 
##                  |     0.050 |     0.340 |           | 
## -----------------|-----------|-----------|-----------|
##     Column Total |        66 |        34 |       100 | 
##                  |     0.660 |     0.340 |           | 
## -----------------|-----------|-----------|-----------|
## 
## </code></pre>
<p>输出表格的第二列(Malignant)为预测阳性，主对角线为预测正确的结果，95%！尽管说我们没有任何医学知识。<br />
出现了5个假阴性的结果。这种情况下，会出现癌症漏查的结果。假阳性为0，也就是说没有正常人误诊断为癌症。</p>
</div>
<div class="section level3">
<h3>提高模型性能</h3>
<p>对于KNN模型来说，我认为有三种方式可能会提升模型性能：</p>
<ul>
<li>改变距离定义<br />
</li>
<li>改变K的取值<br />
</li>
<li>改变变量标准化的方法</li>
</ul>
<p>这里给出一个改变k值的例子,取k = 1,可以看到出现了2个假阳性的情况。</p>
<pre class="r"><code>wbcd_test_pred &lt;- knn(train = wbcd_train, test = wbcd_test,
                      cl = wbcd_train_labels, k=1)
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred,
           prop.chisq=FALSE)</code></pre>
<pre><code>## 
##  
##    Cell Contents
## |-------------------------|
## |                       N |
## |           N / Row Total |
## |           N / Col Total |
## |         N / Table Total |
## |-------------------------|
## 
##  
## Total Observations in Table:  100 
## 
##  
##                  | wbcd_test_pred 
## wbcd_test_labels |    Benign | Malignant | Row Total | 
## -----------------|-----------|-----------|-----------|
##           Benign |        59 |         2 |        61 | 
##                  |     0.967 |     0.033 |     0.610 | 
##                  |     0.952 |     0.053 |           | 
##                  |     0.590 |     0.020 |           | 
## -----------------|-----------|-----------|-----------|
##        Malignant |         3 |        36 |        39 | 
##                  |     0.077 |     0.923 |     0.390 | 
##                  |     0.048 |     0.947 |           | 
##                  |     0.030 |     0.360 |           | 
## -----------------|-----------|-----------|-----------|
##     Column Total |        62 |        38 |       100 | 
##                  |     0.620 |     0.380 |           | 
## -----------------|-----------|-----------|-----------|
## 
## </code></pre>
</div>
</div>
<div class="section level2">
<h2>小结</h2>
<p>一个完整的建模过程一般包含了上面的五个步骤，缺一不可。不同的任务场景，每个步骤的难度也会不一样。 有很多种分类器模型，KNN是最简单的一种，同时也有效。但是我们还是可以看到不足的地方。比如说，模型解释性差（我目前还是不知道该如何评判一个细胞是否是癌细胞），名义变量要进行特殊处理等。</p>
<p><a href="kmean.html">数据模型学习2–聚类分析</a></p>
</div>

<p>Copyright &copy; 2016 Affluence Tan. All rights reserved.</p>



</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
